{"metadata":{"kernelspec":{"display_name":"Python [conda env:notebook] *","language":"python","name":"conda-env-notebook-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /srv/conda/envs/notebook/lib/python3.8/site-packages (2.13.1)\nRequirement already satisfied: h5py>=2.9.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (3.7.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (22.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: astunparse>=1.6.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (65.6.3)\nRequirement already satisfied: absl-py>=1.0.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: flatbuffers>=23.1.21 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (24.3.7)\nRequirement already satisfied: termcolor>=1.1.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (4.4.0)\nRequirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (4.21.12)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (1.62.1)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\nRequirement already satisfied: markdown>=2.6.8 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.2)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.3)\nRequirement already satisfied: rsa<5,>=3.1.4 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.4.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.0.0)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.13)\nRequirement already satisfied: charset-normalizer<3,>=2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.11.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"id":"a3b9641b-b2a1-4863-8f33-35436f2394ab"},{"cell_type":"code","source":"pip install keras-tuner","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting keras-tuner\n  Using cached keras_tuner-1.4.7-py3-none-any.whl (129 kB)\nCollecting kt-legacy\n  Using cached kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.8/site-packages (from keras-tuner) (22.0)\nRequirement already satisfied: keras in /srv/conda/envs/notebook/lib/python3.8/site-packages (from keras-tuner) (2.13.1)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.8/site-packages (from keras-tuner) (2.28.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests->keras-tuner) (1.26.13)\nRequirement already satisfied: charset-normalizer<3,>=2 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests->keras-tuner) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests->keras-tuner) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from requests->keras-tuner) (3.4)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"id":"d531b480-fa7d-40b7-8f8a-20de387593d5"},{"cell_type":"code","source":"# import neccessary tools\nimport pandas as pd\nimport numpy as np\nfrom keras_tuner import HyperModel\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\nfrom keras_tuner.tuners import RandomSearch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":23,"outputs":[],"id":"9e99eef6-01d0-4917-95c8-998f1d0832fb"},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv('FireData.csv')\n\n# The first few rows of the dataset\ndata.head()","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   OBJECTID                                              Shape  FOD_ID  \\\n0         1  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\xce\\n[_@^\\xc0\\x...       1   \n1         2  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\xe594\\xe2\\x19^\\...       2   \n2         3  b'\\x00\\x01\\xad\\x10\\x00\\x00x{\\xac \\x13/^\\xc0@\\x...       3   \n3         4  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\x13u\\xd7s\\xfa]\\...       4   \n4         5  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\x11y\\xf8\\xb6\\xf...       5   \n\n       FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_AGENCY  \\\n0  FS-1418826                FED   FS-FIRESTAT                    FS   \n1  FS-1418827                FED   FS-FIRESTAT                    FS   \n2  FS-1418835                FED   FS-FIRESTAT                    FS   \n3  FS-1418845                FED   FS-FIRESTAT                    FS   \n4  FS-1418847                FED   FS-FIRESTAT                    FS   \n\n  NWCG_REPORTING_UNIT_ID  NWCG_REPORTING_UNIT_NAME  SOURCE_REPORTING_UNIT  \\\n0                USCAPNF    Plumas National Forest                    511   \n1                USCAENF  Eldorado National Forest                    503   \n2                USCAENF  Eldorado National Forest                    503   \n3                USCAENF  Eldorado National Forest                    503   \n4                USCAENF  Eldorado National Forest                    503   \n\n   ...   LATITUDE   LONGITUDE       OWNER_DESCR STATE COUNTY FIPS_CODE  \\\n0  ...  40.036944 -121.005833              USFS    CA   63.0    6063.0   \n1  ...  38.933056 -120.404444              USFS    CA   61.0    6061.0   \n2  ...  38.984167 -120.735556  STATE OR PRIVATE    CA   17.0    6017.0   \n3  ...  38.559167 -119.913333              USFS    CA    3.0    6003.0   \n4  ...  38.559167 -119.933056              USFS    CA    3.0    6003.0   \n\n          FIPS_NAME DURATION_HOURS Precipitation_In_Month Avg_Temp_In_Month  \n0     Plumas County           4.50                   3.69              45.6  \n1     Placer County           6.75                   0.08              60.2  \n2  El Dorado County           1.05                   0.08              60.2  \n3     Alpine County         118.00                   0.06              66.8  \n4     Alpine County         116.00                   0.06              66.8  \n\n[5 rows x 42 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OBJECTID</th>\n      <th>Shape</th>\n      <th>FOD_ID</th>\n      <th>FPA_ID</th>\n      <th>SOURCE_SYSTEM_TYPE</th>\n      <th>SOURCE_SYSTEM</th>\n      <th>NWCG_REPORTING_AGENCY</th>\n      <th>NWCG_REPORTING_UNIT_ID</th>\n      <th>NWCG_REPORTING_UNIT_NAME</th>\n      <th>SOURCE_REPORTING_UNIT</th>\n      <th>...</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>OWNER_DESCR</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>FIPS_CODE</th>\n      <th>FIPS_NAME</th>\n      <th>DURATION_HOURS</th>\n      <th>Precipitation_In_Month</th>\n      <th>Avg_Temp_In_Month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\xce\\n[_@^\\xc0\\x...</td>\n      <td>1</td>\n      <td>FS-1418826</td>\n      <td>FED</td>\n      <td>FS-FIRESTAT</td>\n      <td>FS</td>\n      <td>USCAPNF</td>\n      <td>Plumas National Forest</td>\n      <td>511</td>\n      <td>...</td>\n      <td>40.036944</td>\n      <td>-121.005833</td>\n      <td>USFS</td>\n      <td>CA</td>\n      <td>63.0</td>\n      <td>6063.0</td>\n      <td>Plumas County</td>\n      <td>4.50</td>\n      <td>3.69</td>\n      <td>45.6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\xe594\\xe2\\x19^\\...</td>\n      <td>2</td>\n      <td>FS-1418827</td>\n      <td>FED</td>\n      <td>FS-FIRESTAT</td>\n      <td>FS</td>\n      <td>USCAENF</td>\n      <td>Eldorado National Forest</td>\n      <td>503</td>\n      <td>...</td>\n      <td>38.933056</td>\n      <td>-120.404444</td>\n      <td>USFS</td>\n      <td>CA</td>\n      <td>61.0</td>\n      <td>6061.0</td>\n      <td>Placer County</td>\n      <td>6.75</td>\n      <td>0.08</td>\n      <td>60.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00x{\\xac \\x13/^\\xc0@\\x...</td>\n      <td>3</td>\n      <td>FS-1418835</td>\n      <td>FED</td>\n      <td>FS-FIRESTAT</td>\n      <td>FS</td>\n      <td>USCAENF</td>\n      <td>Eldorado National Forest</td>\n      <td>503</td>\n      <td>...</td>\n      <td>38.984167</td>\n      <td>-120.735556</td>\n      <td>STATE OR PRIVATE</td>\n      <td>CA</td>\n      <td>17.0</td>\n      <td>6017.0</td>\n      <td>El Dorado County</td>\n      <td>1.05</td>\n      <td>0.08</td>\n      <td>60.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xc8\\x13u\\xd7s\\xfa]\\...</td>\n      <td>4</td>\n      <td>FS-1418845</td>\n      <td>FED</td>\n      <td>FS-FIRESTAT</td>\n      <td>FS</td>\n      <td>USCAENF</td>\n      <td>Eldorado National Forest</td>\n      <td>503</td>\n      <td>...</td>\n      <td>38.559167</td>\n      <td>-119.913333</td>\n      <td>USFS</td>\n      <td>CA</td>\n      <td>3.0</td>\n      <td>6003.0</td>\n      <td>Alpine County</td>\n      <td>118.00</td>\n      <td>0.06</td>\n      <td>66.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\x11y\\xf8\\xb6\\xf...</td>\n      <td>5</td>\n      <td>FS-1418847</td>\n      <td>FED</td>\n      <td>FS-FIRESTAT</td>\n      <td>FS</td>\n      <td>USCAENF</td>\n      <td>Eldorado National Forest</td>\n      <td>503</td>\n      <td>...</td>\n      <td>38.559167</td>\n      <td>-119.933056</td>\n      <td>USFS</td>\n      <td>CA</td>\n      <td>3.0</td>\n      <td>6003.0</td>\n      <td>Alpine County</td>\n      <td>116.00</td>\n      <td>0.06</td>\n      <td>66.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 42 columns</p>\n</div>"},"metadata":{}}],"id":"64246d93-122e-4d49-a100-a0f2b1d37609"},{"cell_type":"code","source":"# Select relevant columns including the target variable\ndata_of_interest = ['FIRE_YEAR', 'FIRE_SIZE', 'LATITUDE', 'LONGITUDE', 'Avg_Temp_In_Month', 'Precipitation_In_Month', 'NWCG_GENERAL_CAUSE']\ndata_selected = data[data_of_interest]\n\nX = data_selected.drop('NWCG_GENERAL_CAUSE', axis=1)\ny = data_selected['NWCG_GENERAL_CAUSE']\n\n# One-hot encoder\nonehot_encoder = OneHotEncoder(sparse_output=False)\ny_encoded = onehot_encoder.fit_transform(y.values.reshape(-1, 1))\nprint(onehot_encoder.categories_)\n\n# Split the data into training, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Normalize the features\nnumeric_features = ['FIRE_YEAR', 'FIRE_SIZE', 'LATITUDE', 'LONGITUDE', 'Avg_Temp_In_Month', 'Precipitation_In_Month']\nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\npreprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n\nX_train_transformed = preprocessor.fit_transform(X_train)\nX_val_transformed = preprocessor.transform(X_val)\nX_test_transformed = preprocessor.transform(X_test)","metadata":{"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"[array(['Arson/incendiarism', 'Debris and open burning',\n       'Equipment and vehicle use', 'Firearms and explosives use',\n       'Fireworks', 'Missing data/not specified/undetermined',\n       'Misuse of fire by a minor', 'Natural', 'Other causes',\n       'Power generation/transmission/distribution',\n       'Railroad operations and maintenance', 'Recreation and ceremony',\n       'Smoking'], dtype=object)]\n","output_type":"stream"}],"id":"d202f907-8cd1-462d-9135-05eb44d876f1"},{"cell_type":"code","source":"# Define a class that facilitates finding the best amount of neural nodes and learning rates for the model\n\nclass MyHyperModel(HyperModel):\n    def __init__(self, input_shape, num_classes):\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n\n    def build(self, hp):\n        model = Sequential()\n        model.add(Dense(units=hp.Int('units',\n                                     min_value=32,\n                                     max_value=512,\n                                     step=16),\n                        activation='relu',\n                        input_shape=self.input_shape))\n        model.add(Dense(self.num_classes, activation='softmax'))\n        model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n        return model\n","metadata":{"trusted":true},"execution_count":50,"outputs":[],"id":"0e4c432d-9649-4a0a-89a3-03ea9d23ab5e"},{"cell_type":"code","source":"# Find the best parameters through 100 trials\n\ntuner = RandomSearch(\n    MyHyperModel(input_shape=X_train_transformed.shape[1:], num_classes=y_train.shape[1]),\n    objective='val_accuracy',\n    max_trials=100,\n    executions_per_trial=1,\n    )\n\ntuner.search(X_train_transformed, y_train, epochs=10, validation_data=(X_val_transformed, y_val))","metadata":{"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}],"id":"d7d0a5c9-c088-44b3-9f04-fb514b30926e"},{"cell_type":"code","source":"# Get the best hyperparameters.\nbest_hyperparameters = tuner.get_best_hyperparameters()[0]  # This returns the best set of hyperparameters\n\nprint('Best hyperparameters:', best_hyperparameters.values)\n# Retrieve the best model.\nbest_model = tuner.get_best_models(num_models=1)[0]","metadata":{"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Best hyperparameters: {'units': 416, 'learning_rate': 0.0054654394957180845}\n","output_type":"stream"}],"id":"1d278212-4f1c-4dc6-9356-82be680b2ad2"},{"cell_type":"code","source":"   \"\"\"\n    build_model:\n    \n    Builds a neural network model with L1/L2 regularization.\n\n    Parameters:\n    - n_units: Number of units in the hidden layer.\n    - learning_rate: Learning rate for the optimizer.\n\n    Returns:\n    - A compiled Keras model.\n    \"\"\"\n# Define L1, L2\nl1_reg = 0.0005\nl2_reg = 0.0005\n\ndef build_model(n_units, learning_rate):\n    model = Sequential([\n        Dense(n_units, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n        Dense(n_units, activation='relu', kernel_regularizer=l2(l2_reg)),\n        Dense(y_train.shape[1], activation='softmax') \n    ])\n\n    \n    model.compile(optimizer=Adam(learning_rate=learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true},"execution_count":53,"outputs":[],"id":"5e3ba196-7712-42dc-90b8-e4b0c5cd883a"},{"cell_type":"code","source":"# Recombine the training and validation sets for this final training step to maximize the data the model learns from\nX_full_train = np.concatenate((X_train_transformed, X_val_transformed), axis=0)\ny_full_train = np.concatenate((y_train, y_val), axis=0)\n\n# Extract parameters from the best hyperparameters found earlier\nbest_n_units = best_hyperparameters.get('units')\nbest_learning_rate = best_hyperparameters.get('learning_rate')\n\n# Rebuild the model using the best hyperparameters\nbest_model = build_model(best_n_units, best_learning_rate)\n\n# Retrain the model on the full training dataset\nhistory = best_model.fit(X_full_train, y_full_train, epochs=10, batch_size=16, verbose=2)","metadata":{"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\nWARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\nEpoch 1/10\n530/530 - 6s - loss: 1.4729 - accuracy: 0.5663 - 6s/epoch - 11ms/step\nEpoch 2/10\n530/530 - 5s - loss: 1.3703 - accuracy: 0.5856 - 5s/epoch - 10ms/step\nEpoch 3/10\n530/530 - 5s - loss: 1.3474 - accuracy: 0.5910 - 5s/epoch - 10ms/step\nEpoch 4/10\n530/530 - 5s - loss: 1.3299 - accuracy: 0.5938 - 5s/epoch - 10ms/step\nEpoch 5/10\n530/530 - 5s - loss: 1.3227 - accuracy: 0.5941 - 5s/epoch - 10ms/step\nEpoch 6/10\n530/530 - 5s - loss: 1.3117 - accuracy: 0.5972 - 5s/epoch - 10ms/step\nEpoch 7/10\n530/530 - 5s - loss: 1.3053 - accuracy: 0.6019 - 5s/epoch - 10ms/step\nEpoch 8/10\n530/530 - 5s - loss: 1.2977 - accuracy: 0.6054 - 5s/epoch - 10ms/step\nEpoch 9/10\n530/530 - 5s - loss: 1.2922 - accuracy: 0.6041 - 5s/epoch - 10ms/step\nEpoch 10/10\n530/530 - 5s - loss: 1.2893 - accuracy: 0.6091 - 5s/epoch - 10ms/step\n","output_type":"stream"}],"id":"06ee3fd4-d4c7-4f55-b09d-b29d0ae9fd27"},{"cell_type":"code","source":"# Calculate the average accuracy\naccuracies = history.history['accuracy']\naverage_accuracy = sum(accuracies) / len(accuracies)\n\nprint(f\"Average accuracy over {len(accuracies)} epochs: {average_accuracy}\")","metadata":{"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Average accuracy over 10 epochs: 0.5948499858379364\n","output_type":"stream"}],"id":"be2a2670-2d49-4b26-a6ae-210c28a2e3ee"},{"cell_type":"markdown","source":"# Prediction Demo","metadata":{},"id":"cf06e101-b9cc-4347-bb85-ed8170426481"},{"cell_type":"code","source":"# Example input data (replace with your actual data)\nnew_observation = {\n    'FIRE_YEAR': 2004,\n    'FIRE_SIZE': 0.1,\n    'LATITUDE': 39.69,\n    'LONGITUDE': -120.0,\n    'Avg_Temp_In_Month': 73.2,\n    'Precipitation_In_Month': 0.19\n}\n\ninput_data = np.array([[new_observation[key] for key in sorted(new_observation)]])\n\n# Ensure the input data shape matches what the model expects\n# Example: input_data might need to be reshaped if your model expects a specific dimensionality\n\npredictions = best_model.predict(input_data)\n\n# If your model performs classification, you'll get probabilities for each class\n# Convert probabilities to class labels if necessary\npredicted_class = np.argmax(predictions, axis=1)  # For classification tasks\n\npredicted_class = np.argmax(predictions, axis=1)\nclass_names = ['Arson/incendiarism', 'Debris and open burning',\n       'Equipment and vehicle use', 'Firearms and explosives use',\n       'Fireworks', 'Missing data/not specified/undetermined',\n       'Misuse of fire by a minor', 'Natural', 'Other causes',\n       'Power generation/transmission/distribution',\n       'Railroad operations and maintenance', 'Recreation and ceremony',\n       'Smoking']\npredicted_labels = [class_names[i] for i in predicted_class]\nprint('The cause of the fire is most likely:')\nprint(predicted_labels)\n","metadata":{"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 33ms/step\nThe cause of the fire is most likely:\n['Natural']\n","output_type":"stream"}],"id":"ed6b3371-b026-4744-b1cb-ce9df11a1a6a"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"13394c61-f90d-4349-820f-2de7d4595ee6"}]}
